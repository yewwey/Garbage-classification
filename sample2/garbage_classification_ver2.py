# -*- coding: utf-8 -*-
"""ResNet50V2

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gofFrLOa1O53RjKpdO6mRs9-nAbxIdeu
"""

from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import Dense, Dropout, Flatten, Input
from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import ModelCheckpoint, LambdaCallback, TensorBoard
from sklearn.preprocessing import LabelBinarizer
from tensorflow.nn import local_response_normalization  # lrn
import matplotlib.pyplot as plt
import io
import pandas as pd
from PIL import Image
import numpy as np
from numpy import asarray
import cv2
import glob
import os
import cv2
from tqdm import tqdm
from imutils import paths

"""### 데이터 다운로드"""

!pip install kaggle

from google.colab import files
uploaded = files.upload()
for fn in uploaded.keys():
  print('uploaded file "{name}" with length {length} bytes'.format(
      name=fn, length=len(uploaded[fn])))
  
# kaggle.json을 아래 폴더로 옮긴 뒤, file을 사용할 수 있도록 권한을 부여한다. 
!mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json

ls -1ha ~/.kaggle/kaggle.json

# Commented out IPython magic to ensure Python compatibility.
from os.path import join  

DRIVE_PATH = '/content/drive/Shareddrives/yeja/Garbage classification/data' # DRIVE path 정의
# %cd "{DRIVE_PATH}"# 안으로

!kaggle datasets download -d mostafaabla/garbage-classification

!ls

# !unzip garbage-classification.zip

"""### 데이터 부풀리기"""

import numpy as np
import os

# 랜덤시드 고정시키기
np.random.seed(5)
from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img

# 데이터셋 불러오기
data_aug_gen = ImageDataGenerator(rescale=1./255, 
                                  rotation_range=15,
                                  width_shift_range=0.1,
                                  height_shift_range=0.1,
                                  shear_range=0.5,
                                  zoom_range=[0.8, 2.0],
                                  horizontal_flip=True,
                                  vertical_flip=True,
                                  fill_mode='nearest')
path = '/content/drive/Shareddrives/yeja/Garbage classification/data/garbage_classification/brown-glass'
file_list = os.listdir(path)
for i in file_list:
    img = load_img('/content/drive/Shareddrives/yeja/Garbage classification/data/garbage_classification/brown-glass/%s'%i)
    x = img_to_array(img)
    x = x.reshape((1,) + x.shape)

    count = 0
# 이 for는 무한으로 반복되기 때문에 우리가 원하는 반복횟수를 지정하여, 지정된 반복횟수가 되면 빠져나오도록 해야합니다.
    for batch in data_aug_gen.flow(x, batch_size=1, save_to_dir='/content/drive/Shareddrives/yeja/Garbage classification/data/data/glass/', save_prefix='tri', save_format='jpg'):
        count += 1
        if count > 8:
            break

import numpy as np
import os

# 랜덤시드 고정시키기
np.random.seed(5)
from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img

# 데이터셋 불러오기
data_aug_gen = ImageDataGenerator(rescale=1./255, 
                                  rotation_range=15,
                                  width_shift_range=0.1,
                                  height_shift_range=0.1,
                                  shear_range=0.5,
                                  zoom_range=[0.8, 2.0],
                                  horizontal_flip=True,
                                  vertical_flip=True,
                                  fill_mode='nearest')
path = '/content/drive/Shareddrives/yeja/Garbage classification/data/garbage_classification/green-glass'
file_list = os.listdir(path)
for i in file_list:
    img = load_img('/content/drive/Shareddrives/yeja/Garbage classification/data/garbage_classification/green-glass/%s'%i)
    x = img_to_array(img)
    x = x.reshape((1,) + x.shape)

    count = 0
# 이 for는 무한으로 반복되기 때문에 우리가 원하는 반복횟수를 지정하여, 지정된 반복횟수가 되면 빠져나오도록 해야합니다.
    for batch in data_aug_gen.flow(x, batch_size=1, save_to_dir='/content/drive/Shareddrives/yeja/Garbage classification/data/data/glass/', save_prefix='tri', save_format='jpg'):
        count += 1
        if count > 8:
            break
print("Complete")

import numpy as np
import os

# 랜덤시드 고정시키기
np.random.seed(5)
from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img

# 데이터셋 불러오기
data_aug_gen = ImageDataGenerator(rescale=1./255, 
                                  rotation_range=15,
                                  width_shift_range=0.1,
                                  height_shift_range=0.1,
                                  shear_range=0.5,
                                  zoom_range=[0.8, 2.0],
                                  horizontal_flip=True,
                                  vertical_flip=True,
                                  fill_mode='nearest')
path = '/content/drive/Shareddrives/yeja/Garbage classification/data/garbage_classification/white-glass'
file_list = os.listdir(path)
for i in file_list:
    img = load_img('/content/drive/Shareddrives/yeja/Garbage classification/data/garbage_classification/white-glass/%s'%i)
    x = img_to_array(img)
    x = x.reshape((1,) + x.shape)

    count = 0
# 이 for는 무한으로 반복되기 때문에 우리가 원하는 반복횟수를 지정하여, 지정된 반복횟수가 되면 빠져나오도록 해야합니다.
    for batch in data_aug_gen.flow(x, batch_size=1, save_to_dir='/content/drive/Shareddrives/yeja/Garbage classification/data/data/glass/', save_prefix='tri', save_format='jpg'):
        count += 1
        if count > 8:
            break

import numpy as np
import os

# 랜덤시드 고정시키기
np.random.seed(5)
from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img

# 데이터셋 불러오기
data_aug_gen = ImageDataGenerator(rescale=1./255, 
                                  rotation_range=15,
                                  width_shift_range=0.1,
                                  height_shift_range=0.1,
                                  shear_range=0.5,
                                  zoom_range=[0.8, 2.0],
                                  horizontal_flip=True,
                                  vertical_flip=True,
                                  fill_mode='nearest')
path = '/content/drive/Shareddrives/yeja/Garbage classification/glass'
file_list = os.listdir(path)
for i in file_list:
    img = load_img('/content/drive/Shareddrives/yeja/Garbage classification/glass/%s'%i)
    x = img_to_array(img)
    x = x.reshape((1,) + x.shape)

    count = 0
# 이 for는 무한으로 반복되기 때문에 우리가 원하는 반복횟수를 지정하여, 지정된 반복횟수가 되면 빠져나오도록 해야합니다.
    for batch in data_aug_gen.flow(x, batch_size=1, save_to_dir='/content/drive/Shareddrives/yeja/Garbage classification/data/data/glass/', save_prefix='tri', save_format='jpg'):
        count += 1
        if count > 8:
            break

from imutils import paths

search_dir = "/content/drive/Shareddrives/yeja/Garbage classification/data/data/paper"

image_paths = sorted(
    list(paths.list_images(search_dir))
)

print(">>> image count =", len(image_paths))
print(image_paths)

import numpy as np
import os

# 랜덤시드 고정시키기
np.random.seed(5)
from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img

# 데이터셋 불러오기
train_datagen = ImageDataGenerator(rescale=1./255)
data_aug_gen = ImageDataGenerator(rescale=1./255, 
                                  rotation_range=15,
                                  width_shift_range=0.1,
                                  height_shift_range=0.1,
                                  shear_range=0.5,
                                  zoom_range=[0.8, 2.0],
                                  horizontal_flip=True,
                                  vertical_flip=True,
                                  fill_mode='nearest')
path = '/content/drive/Shareddrives/yeja/Garbage classification/data/garbage_classification/metal'
file_list = os.listdir(path)
for i in file_list:
    img = load_img('/content/drive/Shareddrives/yeja/Garbage classification/data/garbage_classification/metal/%s'%i)
    x = img_to_array(img)
    x = x.reshape((1,) + x.shape)

    count = 0
# 이 for는 무한으로 반복되기 때문에 우리가 원하는 반복횟수를 지정하여, 지정된 반복횟수가 되면 빠져나오도록 해야합니다.
    for batch in data_aug_gen.flow(x, batch_size=1, save_to_dir='/content/drive/Shareddrives/yeja/Garbage classification/data/data/metal/', save_prefix='tri', save_format='jpg'):
        count += 1
        if count > 12:
            break
print("complete")

import numpy as np
import os

# 랜덤시드 고정시키기
np.random.seed(5)
from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img

# 데이터셋 불러오기
train_datagen = ImageDataGenerator(rescale=1./255)
data_aug_gen = ImageDataGenerator(rescale=1./255, 
                                  rotation_range=15,
                                  width_shift_range=0.1,
                                  height_shift_range=0.1,
                                  shear_range=0.5,
                                  zoom_range=[0.8, 2.0],
                                  horizontal_flip=True,
                                  vertical_flip=True,
                                  fill_mode='nearest')
path = '/content/drive/Shareddrives/yeja/Garbage classification/data/garbage_classification/paper'
file_list = os.listdir(path)
for i in file_list:
    img = load_img('/content/drive/Shareddrives/yeja/Garbage classification/data/garbage_classification/paper/%s'%i)
    x = img_to_array(img)
    x = x.reshape((1,) + x.shape)

    count = 0
# 이 for는 무한으로 반복되기 때문에 우리가 원하는 반복횟수를 지정하여, 지정된 반복횟수가 되면 빠져나오도록 해야합니다.
    for batch in data_aug_gen.flow(x, batch_size=1, save_to_dir='/content/drive/Shareddrives/yeja/Garbage classification/data/data/paper/', save_prefix='tri', save_format='jpg'):
        count += 1
        if count > 15:
            break
print("complete")

import numpy as np
import os

# 랜덤시드 고정시키기
np.random.seed(5)
from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img

# 데이터셋 불러오기
train_datagen = ImageDataGenerator(rescale=1./255)
data_aug_gen = ImageDataGenerator(rescale=1./255, 
                                  rotation_range=15,
                                  width_shift_range=0.1,
                                  height_shift_range=0.1,
                                  shear_range=0.5,
                                  zoom_range=[0.8, 2.0],
                                  horizontal_flip=True,
                                  vertical_flip=True,
                                  fill_mode='nearest')
path = '/content/drive/Shareddrives/yeja/Garbage classification/data/garbage_classification/plastic'
file_list = os.listdir(path)
for i in file_list:
    img = load_img('/content/drive/Shareddrives/yeja/Garbage classification/data/garbage_classification/plastic/%s'%i)
    x = img_to_array(img)
    x = x.reshape((1,) + x.shape)

    count = 0
# 이 for는 무한으로 반복되기 때문에 우리가 원하는 반복횟수를 지정하여, 지정된 반복횟수가 되면 빠져나오도록 해야합니다.
    for batch in data_aug_gen.flow(x, batch_size=1, save_to_dir='/content/drive/Shareddrives/yeja/Garbage classification/data/data/plastic/', save_prefix='tri', save_format='jpg'):
        count += 1
        if count > 12:
            break
print("complete")

"""### 데이터 배열 안에 넣기"""

import os
import cv2
from tqdm import tqdm
from imutils import paths

search_dir = "/content/drive/Shareddrives/yeja/Garbage classification/cardboard_copy"

image_paths = sorted(
    list(paths.list_images(search_dir))
)
image_dim = (150, 150, 3)
labels = []
images = []
for image_path in tqdm(image_paths):
    image = cv2.imread(image_path)

    image = cv2.resize(
        image, (image_dim[1], image_dim[0])
    )
    images.append(image)
    
    label = "cardboard"
    labels.append([label])
    
print(">>> images count =", len(images))

search_dir = "/content/drive/Shareddrives/yeja/Garbage classification/data/data/paper"

image_paths = sorted(
    list(paths.list_images(search_dir))
)

for image_path in tqdm(image_paths):
    image = cv2.imread(image_path)

    image = cv2.resize(
        image, (image_dim[1], image_dim[0])
    )
    images.append(image)
    
    label = "paper"
    labels.append([label])
    
search_dir = "/content/drive/Shareddrives/yeja/Garbage classification/data/data/glass"

image_paths = sorted(
    list(paths.list_images(search_dir))
)

for image_path in tqdm(image_paths):
    image = cv2.imread(image_path)

    image = cv2.resize(
        image, (image_dim[1], image_dim[0])
    )
    images.append(image)
    
    label = "glass"
    labels.append([label])

search_dir = "/content/drive/Shareddrives/yeja/Garbage classification/data/data/metal"

image_paths = sorted(
    list(paths.list_images(search_dir))
)

for image_path in tqdm(image_paths):
    image = cv2.imread(image_path)

    image = cv2.resize(
        image, (image_dim[1], image_dim[0])
    )
    images.append(image)
    
    label = "metal"
    labels.append([label])
    
print(">>> images count =", len(images))

search_dir = "/content/drive/Shareddrives/yeja/Garbage classification/data/data/plastic"

image_paths = sorted(
    list(paths.list_images(search_dir))
)

for image_path in tqdm(image_paths):
    image = cv2.imread(image_path)

    image = cv2.resize(
        image, (image_dim[1], image_dim[0])
    )
    images.append(image)
    
    label = "plastic"
    labels.append([label])
    
print(">>> images count =", len(images))

search_dir = "/content/drive/Shareddrives/yeja/Garbage classification/trash_copy"

image_paths = sorted(
    list(paths.list_images(search_dir))
)

for image_path in tqdm(image_paths):
    image = cv2.imread(image_path)

    image = cv2.resize(
        image, (image_dim[1], image_dim[0])
    )
    images.append(image)
    
    label = "trash"
    labels.append([label])
    
print(">>> images count =", len(images))

"""### 전처리 및 분할"""

import numpy as np
from sklearn.preprocessing import MultiLabelBinarizer
from sklearn.model_selection import train_test_split

images = np.array(images, dtype='float32')/255.0
labels = np.array(labels)

mlb = MultiLabelBinarizer()
enc_labels = mlb.fit_transform(labels)

print(">>> classes name =", mlb.classes_)

x_train = images
y_train = enc_labels

"""### test, val"""

import os
import cv2
from tqdm import tqdm
from imutils import paths

search_dir = "/content/drive/Shareddrives/yeja/Garbage classification/cardboard"

image_dim = (150, 150, 3)

image_paths = sorted(
    list(paths.list_images(search_dir))
)
test_labels = []
test_images = []
for image_path in tqdm(image_paths):
    test_image = cv2.imread(image_path)

    test_image = cv2.resize(
        test_image, (image_dim[1], image_dim[0])
    )
    test_images.append(test_image)
    
    test_label = "cardboard"
    test_labels.append([test_label])
    
print(">>> images count =", len(test_images))
search_dir = "/content/drive/Shareddrives/yeja/Garbage classification/glass"

image_paths = sorted(
    list(paths.list_images(search_dir))
)
for image_path in tqdm(image_paths):
    test_image = cv2.imread(image_path)

    test_image = cv2.resize(
        test_image, (image_dim[1], image_dim[0])
    )
    test_images.append(test_image)
    
    test_label = "glass"
    test_labels.append([test_label])
    
print(">>> images count =", len(test_images))
search_dir = "/content/drive/Shareddrives/yeja/Garbage classification/data/garbage_classification/metal"

image_paths = sorted(
    list(paths.list_images(search_dir))
)
for image_path in tqdm(image_paths):
    test_image = cv2.imread(image_path)

    test_image = cv2.resize(
        test_image, (image_dim[1], image_dim[0])
    )
    test_images.append(test_image)
    
    test_label = "metal"
    test_labels.append([test_label])
    
print(">>> images count =", len(test_images))
search_dir = "/content/drive/Shareddrives/yeja/Garbage classification/data/garbage_classification/paper"

image_paths = sorted(
    list(paths.list_images(search_dir))
)
for image_path in tqdm(image_paths):
    test_image = cv2.imread(image_path)

    test_image = cv2.resize(
        test_image, (image_dim[1], image_dim[0])
    )
    test_images.append(test_image)
    
    test_label = "paper"
    test_labels.append([test_label])
    
print(">>> images count =", len(test_images))
search_dir = "/content/drive/Shareddrives/yeja/Garbage classification/data/garbage_classification/plastic"

image_paths = sorted(
    list(paths.list_images(search_dir))
)
for image_path in tqdm(image_paths):
    test_image = cv2.imread(image_path)

    test_image = cv2.resize(
        test_image, (image_dim[1], image_dim[0])
    )
    test_images.append(test_image)
    
    test_label = "plastic"
    test_labels.append([test_label])
    
print(">>> images count =", len(test_images))
search_dir = "/content/drive/Shareddrives/yeja/Garbage classification/trash"

image_paths = sorted(
    list(paths.list_images(search_dir))
)
for image_path in tqdm(image_paths):
    test_image = cv2.imread(image_path)

    test_image = cv2.resize(
        test_image, (image_dim[1], image_dim[0])
    )
    test_images.append(test_image)
    
    test_label = "trash"
    test_labels.append([test_label])
    
print(">>> images count =", len(test_images))
print(len(test_labels))

import numpy as np
from sklearn.preprocessing import MultiLabelBinarizer
from sklearn.model_selection import train_test_split

test_images = np.array(test_images, dtype='float32')/255.0
test_labels = np.array(test_labels)

mlb = MultiLabelBinarizer()
test_enc_labels = mlb.fit_transform(test_labels)

print(">>> classes name =", mlb.classes_)

seed = 27

(x_test, x_val, y_test, y_val) = train_test_split(
    test_images, test_enc_labels, test_size=0.2, random_state=seed
)
print(">> test test shape = {} {}".format(
    x_test.shape, y_test.shape)
)

"""### 모델 구성 & 학습"""

import tensorflow as tf
model = tf.keras.applications.ResNet50V2(include_top=False,input_shape=(150, 150, 3))

flat1 = Flatten()(model.layers[-1].output)
class1 = Dense(2048, activation='relu')(flat1)
output = Dense(6, activation='softmax')(class1)
# define new model
model = Model(inputs=model.inputs, outputs=output)

model.summary()

#모델 학습
model.compile(loss='categorical_crossentropy',
              optimizer=Adam(),
              metrics=['accuracy'])

hist = model.fit(x_train, y_train,
                    batch_size=16,
                    epochs=100, 
                    verbose=1,
                    validation_data=(x_val, y_val))

# Commented out IPython magic to ensure Python compatibility.
#loss & accuracy 시각화
# %matplotlib inline
import matplotlib.pyplot as plt

fig, loss_ax = plt.subplots()

acc_ax = loss_ax.twinx()

loss_ax.plot(hist.history['loss'], 'r', label='train loss')
loss_ax.plot(hist.history['val_loss'], 'g', label='val loss')

acc_ax.plot(hist.history['accuracy'], 'b', label='train acc')
acc_ax.plot(hist.history['val_accuracy'], 'y', label='val acc')

loss_ax.set_xlabel('epoch')
loss_ax.set_ylabel('loss')
acc_ax.set_ylabel('accuray')

loss_ax.legend(loc='upper left')
acc_ax.legend(loc='lower left')

plt.show()

loss_and_metrics = model.evaluate(x_test, y_test, batch_size=16)
print('')
print('loss_and_metrics : ' + str(loss_and_metrics))

#모델 저장
from keras.models import load_model
model.save('/content/drive/Shareddrives/yeja/Garbage classification/garbage_classification_model_ver2.h5')

#모델 Architecture
from tensorflow.keras.utils import plot_model

plot_model(model, to_file='/content/drive/Shareddrives/yeja/Garbage classification/sample2_model_architecture.png')
plot_model(model, to_file='/content/drive/Shareddrives/yeja/Garbage classification/sample2_model_shapes.png', show_shapes=True)

"""### 모델 불러오기"""

from keras.models import load_model
model = load_model('/content/drive/Shareddrives/yeja/Garbage classification/garbage_classification_model_ver9.h5')

from google.colab import drive
drive.mount('/content/drive')

predictions = model.predict(x_test, verbose=1)

# 데이터 테스트
def load_label_names():
    return ['cardboard', 'glass', 'metal', 'paper', 'plastic', 'trash']

def display_image_predictions(features, labels, predictions):
    n_classes = 6
    label_names = load_label_names()
    label_binarizer = LabelBinarizer()
    label_binarizer.fit(range(n_classes))
    label_ids = label_binarizer.inverse_transform(np.array(labels))

    fig, axs = plt.subplots(6, 2, figsize=(12,24))
    margin = 0.05
    ind = np.arange(n_classes)
    width = (1. - 2. * margin) / n_classes    
    arr_features = [None]*10
    arr_predictions = np.zeros((6, 6))
    last_image_i = 0
    
    for i, prediction in enumerate(predictions):
        label_id = label_ids[i]
        feature = features[i]
        arr_features[label_id] = feature
        max_id = np.argmax(prediction)
        arr_predictions[label_id][max_id] += 1
        last_image_i = i

    arr_predictions /= last_image_i
    
    for i in range(6):
      feature = arr_features[i]
      pred_name = label_names[i]
      prediction = arr_predictions[i]
      axs[i][0].imshow(feature)
      axs[i][0].set_title(pred_name)
      axs[i][0].set_axis_off()

      axs[i][1].barh(ind + margin, prediction, width)
      axs[i][1].set_yticks(ind + margin)
      axs[i][1].set_yticklabels(label_names)

    plt.tight_layout()

display_image_predictions(x_test, y_test, predictions)

import os
import cv2
from tqdm import tqdm

def image2array(x_test):
  images1 = []
  labels = []
  x_test = cv2.imread(x_test)
  image1 = cv2.resize(x_test, (150, 150))
  images1.append(image1)
  x_test = np.array(image1, dtype='float32')/255.0
  return x_test

import cv2
import tensorflow as tf

CATEGORIES = ['cardboard', 'glass', 'metal', 'paper', 'plastic', 'trash']
f = '/content/drive/Shareddrives/yeja/Garbage classification/test_image/'


import os
for filename in os.listdir(f):
  filename = os.path.join(f, filename)
  print(filename)
  x_test = image2array(filename)
  test_shape = x_test.shape
  x_test = x_test.reshape(1, test_shape[0], test_shape[1], test_shape[2])
  predictions = model.predict(x_test)
  print(predictions)
  max_id = np.argmax(predictions)
  print(max_id)
  x_test = x_test.reshape(test_shape[0], test_shape[1], test_shape[2])
  plt.imshow(x_test)
  plt.show()
  print('Predicted Result = ' + CATEGORIES[max_id])

